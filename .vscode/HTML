repair-agent/
├─ backend/
│  ├─ package.json{
  "name": "repair-agent-backend",
  "version": "1.0.0",
  "description": "Repair Agent Pro - backend server",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js"
  },
  "keywords": [],
  "author": "You",
  "license": "MIT",
  "dependencies": {
    "cors": "^2.8.5",
    "dotenv": "^16.0.0",
    "express": "^4.18.2",
    "node-fetch": "^3.4.0",
    "openai": "^4.0.0",
    "multer": "^1.4.5-lts.1"
  },
  "devDependencies": {
    "nodemon": "^2.0.22"
  }
}

│  ├─ server.js// server.js
require("dotenv").config();
const express = require("express");
const cors = require("cors");
const apiRoutes = require("./routes/api");

const app = express();
const PORT = process.env.PORT || 4000;

// Basic middleware
app.use(cors());
app.use(express.json({ limit: "1mb" }));
app.use(express.urlencoded({ extended: true }));

// API routes
app.use("/api", apiRoutes);

// static front-end serve (optional)
// If you later copy frontend build into backend/public you can serve it:
app.use(express.static("../frontend"));

app.get("/", (req, res) => {
  res.json({ status: "Repair Agent backend running" });
});

app.listen(PORT, () => {
  console.log(`Repair Agent backend listening on http://localhost:${PORT}`);
});

│  ├─ routes/
│  │  └─ api.js// routes/api.js
const express = require("express");
const router = express.Router();
const { createClient } = require("../utils/openaiClient");
const multer = require("multer");
const upload = multer(); // in-memory (for simple file upload support)

router.get("/health", (req, res) => {
  res.json({ status: "ok", timestamp: Date.now() });
});

/**
 * POST /api/chat
 * Body: { message: string, context?: [] }
 * Returns assistant reply
 */
router.post("/chat", async (req, res) => {
  try {
    const { message, context } = req.body;
    if (!message || typeof message !== "string") {
      return res.status(400).json({ error: "Missing `message` in body." });
    }

    const client = createClient();

    // Use a chat completion request
    const messages = [
      { role: "system", content: "You are Repair Agent Pro assistant. Help users debug phone repairs, guide steps clearly and concisely." },
      ...(Array.isArray(context) ? context : []),
      { role: "user", content: message }
    ];

    const resp = await client.createChatCompletion({
      model: "gpt-4o-mini", // replace with preferred model available to you
      messages,
      max_tokens: 800,
      temperature: 0.2
    });

    // openai library returns data.choices[0].message.content
    const reply = resp.data.choices?.[0]?.message?.content ?? "";

    res.json({ reply });
  } catch (err) {
    console.error("chat error:", err.message || err);
    res.status(500).json({ error: "Server error", details: err.message || err });
  }
});

/**
 * POST /api/upload
 * Simple placeholder for file upload (e.g., logs, screenshots)
 */
router.post("/upload", upload.single("file"), async (req, res) => {
  try {
    if (!req.file) return res.status(400).json({ error: "No file uploaded." });
    // For now we just return basic metadata. You can extend to save to disk or cloud.
    res.json({
      filename: req.file.originalname,
      size: req.file.size,
      mimetype: req.file.mimetype
    });
  } catch (err) {
    console.error("upload error:", err);
    res.status(500).json({ error: "Upload failed" });
  }
});

module.exports = router;

│  ├─ utils/
│  │  └─ openaiClient.js// utils/openaiClient.js
const { Configuration, OpenAIApi } = require("openai");

function createClient() {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) throw new Error("OPENAI_API_KEY= sk-proj-xxxxx.");
  const config = new Configuration({ apiKey });
  return new OpenAIApi(config);
}

module.exports = { createClient };

│  ├─ .env.example# Copy this file to .env and fill
OPENAI_API_KEY=sk-proj-xxxxxxx
PORT=4000

│  └─ README.mdRepair Agent Pro — Backend

1. Copy .env.example to .env and set OPENAI_API_KEY and PORT
2. npm install
3. npm run dev   (or npm start)

Endpoints:
GET /api/health
POST /api/chat { message: string, context?: [] }
POST /api/upload (form-data file)

├─ frontend/
│  ├─ index.html<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Repair Agent Pro — Demo</title>
  <link rel="stylesheet" href="style.css"/>
</head>
<body>
  <div class="app">
    <header>
      <h1>Repair Agent Pro</h1>
      <p class="sub">Ask for repair help, diagnostics, and step-by-step guides</p>
    </header>

    <main id="chat">
      <div id="messages" class="messages"></div>

      <form id="chatForm" class="chat-form">
        <input id="inputMsg" autocomplete="off" placeholder="Describe the problem (e.g., 'Android stuck at FRP screen')" />
        <button id="sendBtn" type="submit">Send</button>
      </form>
    </main>

    <footer>
      <small>Backend proxy at <code>/api/chat</code>. Keep your OpenAI key on server only.</small>
    </footer>
  </div>

  <script src="main.js"></script>
</body>
</html>

│  ├─ style.css/* style.css - simple responsive chat UI */
:root{
  --bg:#f7f9fb;
  --card:#ffffff;
  --accent:#0a66c2;
  --text:#222;
}

*{box-sizing:border-box}
body{
  font-family:Inter, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
  margin:0;
  background:var(--bg);
  color:var(--text);
  display:flex;
  min-height:100vh;
  align-items:center;
  justify-content:center;
}

.app{
  width:100%;
  max-width:840px;
  margin:24px;
  background:var(--card);
  border-radius:12px;
  box-shadow:0 6px 30px rgba(20,30,40,0.08);
  overflow:hidden;
}

header{
  padding:20px;
  border-bottom:1px solid #eee;
}
header h1{margin:0;font-size:20px}
header .sub{margin:4px 0 0;color:#666;font-size:13px}

main#chat{
  padding:16px;
  display:flex;
  flex-direction:column;
  height:520px;
}

.messages{
  flex:1;
  overflow:auto;
  padding-right:8px;
}

.msg{
  margin-bottom:12px;
  display:flex;
  gap:10px;
}
.msg.user .bubble{
  background:linear-gradient(90deg,#e6f0ff,#d9eeff);
  margin-left:auto;
  color:#062240;
}
.msg.assistant .bubble{
  background:#f3f5f7;
  color:#111;
}

.bubble{
  padding:10px 14px;
  border-radius:8px;
  max-width:78%;
  line-height:1.4;
  box-shadow:0 1px 0 rgba(0,0,0,0.02);
  font-size:14px;
}

.chat-form{
  display:flex;
  gap:8px;
  margin-top:12px;
}
.chat-form input{
  flex:1;
  padding:12px;
  border-radius:8px;
  border:1px solid #e6e9ee;
  font-size:14px;
}
.chat-form button{
  background:var(--accent);
  color:#fff;
  border:none;
  padding:0 18px;
  border-radius:8px;
  cursor:pointer;
}

footer }padding:12px;border-top:1px solid #f1f1f1;font-size:12px;color:#666}

│  └─ main.js// main.js - minimal front-end logic to talk to backend /api/chat
const messagesEl = document.getElementById("messages");
const form = document.getElementById("chatForm");
const input = document.getElementById("inputMsg");

function appendMessage(content, role = "assistant") {
  const wrapper = document.createElement("div");
  wrapper.className = `msg ${role}`;
  const bubble = document.createElement("div");
  bubble.className = "bubble";
  bubble.innerHTML = content.replace(/\n/g, "<br/>");
  wrapper.appendChild(bubble);
  messagesEl.appendChild(wrapper);
  messagesEl.scrollTop = messagesEl.scrollHeight;
}

async function sendMessage(text) {
  appendMessage(text, "user");
  appendMessage("Thinking...", "assistant");
  try {
    const resp = await fetch("/api/chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ message: text })
    });
    const data = await resp.json();
    // remove last "Thinking..." bubble
    const assistantBubbles = Array.from(messagesEl.querySelectorAll(".msg.assistant .bubble"));
    const lastAssistantBubble = assistantBubbles[assistantBubbles.length - 1];
    if (lastAssistantBubble) lastAssistantBubble.innerText = data.reply || (data.error ? ("Error: " + data.error) : "No reply.");
  } catch (err) {
    console.error(err);
    appendMessage("Network error. Is the backend running?", "assistant");
  }
}

form.addEventListener("submit", (e) => {
  e.preventDefault();
  const text = input.value.trim();
  if (!text) return;
  input.value = "";
  sendMessage(text);
});

// welcome message
appendMessage("Hello — I am Repair Agent Pro. Ask me about phone repairs, diagnostics, or how to recover accounts. Include model + OS where possible.", "assistant");

└─ README.md# Repair Agent ProRepair Agent Pro - Full project (backend + frontend)

1) Backend
cd backend
cp .env.example .env
# Edit .env and set OPENAI_API_KEY
npm install
npm run dev   # uses nodemon;
# or: npm start

2) Frontend (served separately or via backend static)
Open frontend/index.html in a browser (if backend on a different origin, update fetch URL in frontend/main.js to http://localhost:4000/api/chat)

By default the backend expects frontend to call /api/chat on same origin. If you serve frontend files from the backend (copy frontend to backend/public), you can use express.static to serve them.


1. Copy .env.example to .env and fill in your OpenAI API key.
